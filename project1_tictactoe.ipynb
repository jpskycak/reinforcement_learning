{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class State():\n",
    "    def __init__(self, string_or_array):\n",
    "        if type(string_or_array) == str:\n",
    "            self.string = string_or_array\n",
    "            self.array = np.array(list(string_or_array)).reshape(3,3)\n",
    "        elif type(string_or_array) == np.ndarray:\n",
    "            self.array = string_or_array\n",
    "            self.string = ''.join(string_or_array.flatten())\n",
    "    \n",
    "    def board(self):\n",
    "        return \" {0} | {1} | {2} \\n-----------\\n {3} | {4} | {5} \\n-----------\\n {6} | {7} | {8} \".format(*self.array.flatten())\n",
    "    \n",
    "    def player(self):\n",
    "        if (self.array=='x').sum() > (self.array=='o').sum():\n",
    "            return 'o'\n",
    "        else:\n",
    "            return 'x'\n",
    "    \n",
    "    def winner(self):\n",
    "        x = (self.array == 'x')\n",
    "        o = (self.array == 'o')\n",
    "    \n",
    "        x_triples = x.prod(axis=0).sum() + x.prod(axis=1).sum() + np.diag(x).prod() + np.diag(x.transpose()).prod()\n",
    "        o_triples = o.prod(axis=0).sum() + o.prod(axis=1).sum() + np.diag(o).prod() + np.diag(o.transpose()).prod()\n",
    "        \n",
    "        if x_triples > 0 and o_triples == 0:\n",
    "            return 'x'\n",
    "        elif o_triples > 0 and x_triples == 0:\n",
    "            return 'o'\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def actions(self):\n",
    "        if not self.winner():\n",
    "            return zip(np.where(self.array == ' ')[0], np.where(self.array == ' ')[1])\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    def is_terminal(self):\n",
    "        return len(self.actions())==0\n",
    "    \n",
    "    def transitions(self):\n",
    "        return [{'player': self.player(), 'action': action} for action in self.actions()]\n",
    "    \n",
    "    def result(self,transition):\n",
    "        newstate = self.array.copy()\n",
    "        newstate[transition['action']] = transition['player']\n",
    "        return newstate\n",
    "    \n",
    "class Tree():\n",
    "    def __init__(self):\n",
    "        nodes = {0: ['         ']}\n",
    "        edges = {}\n",
    "        \n",
    "        for i in range(1,10):\n",
    "            newnodes = []\n",
    "            newedges = []\n",
    "            for istring, string in enumerate(nodes[i-1]):\n",
    "                #start_time = time.clock()\n",
    "                state = State(string)\n",
    "                newedges.append([])\n",
    "                for itransition, transition in enumerate(state.transitions()):\n",
    "                    newstate = State(state.result(transition))\n",
    "                    newstring = newstate.string\n",
    "                    try:\n",
    "                        newedges[istring].append(newnodes.index(newstring))\n",
    "                    except:\n",
    "                        newnodes.append(newstring)\n",
    "                        newedges[istring].append(itransition)\n",
    "                nodes[i] = newnodes\n",
    "                edges[i-1] = newedges\n",
    "                #end_time = time.clock()\n",
    "            \n",
    "            #print '   level {0} constructed | duration: {1} | N: {2}'.format(*[i,end_time-start_time,len(newnodes)])\n",
    "            \n",
    "            self.nodes = nodes\n",
    "            self.edges = edges\n",
    "    \n",
    "    def index(self, node):\n",
    "        for i in range(10):\n",
    "            try:\n",
    "                index = {'level':i,'node_number': self.nodes[i].index(node)}\n",
    "            except:\n",
    "                pass\n",
    "        return index\n",
    "    \n",
    "class Agent():\n",
    "    def __init__(self, name, random_frequency, learning_rate, node = '         '):\n",
    "        self.name = name\n",
    "        self.random_frequency = random_frequency\n",
    "        self.learning_rate = learning_rate\n",
    "        self.game_node = '         '\n",
    "        self.selected_node = None\n",
    "        self.previous_value = None\n",
    "        \n",
    "        tree = Tree()\n",
    "        if name == 'x':\n",
    "            tree.nodes = {k:v for k,v in tree.nodes.iteritems() if k%2 == 0}\n",
    "            tree.edges = {k:v for k,v in tree.edges.iteritems() if k%2 == 0}\n",
    "        elif name == 'o':\n",
    "            tree.nodes = {k:v for k,v in tree.nodes.iteritems() if k%2 == 1}\n",
    "            tree.edges = {k:v for k,v in tree.edges.iteritems() if k%2 == 1}\n",
    "        self.tree = tree\n",
    "        \n",
    "        values = {}\n",
    "        for level, nodes in tree.nodes.iteritems():\n",
    "            newvalues = []\n",
    "            for inode, node in enumerate(nodes):\n",
    "                if State(node).is_terminal():\n",
    "                    if State(node).winner() == name:\n",
    "                        newvalues.append(1.)\n",
    "                    else:\n",
    "                        newvalues.append(0.)\n",
    "                else:\n",
    "                    newvalues.append(np.random.rand())  \n",
    "            values[level] = newvalues\n",
    "        self.values = values\n",
    "    \n",
    "    def prospects(self):\n",
    "        game_index = self.tree.index(self.game_node)\n",
    "        i, n = game_index['level'], game_index['node_number']\n",
    "        prospective_node_numbers = self.tree.edges[i][n]\n",
    "        prospective_nodes_values = {self.tree.nodes[i+1][node_num]: self.values[i+1][node_num] for node_num in prospective_node_numbers}\n",
    "        return prospective_nodes_values\n",
    "\n",
    "    def greedy_node(self):\n",
    "        d = self.prospects()\n",
    "        return max(d.iterkeys(), key=(lambda key: d[key]))\n",
    "    \n",
    "    def random_node(self):\n",
    "        return random.choice(self.prospects().keys())\n",
    "    \n",
    "    def make_move(self):\n",
    "        if np.random.rand() < self.random_frequency:\n",
    "            self.selected_node = self.random_node()\n",
    "            self.game_node = self.selected_node\n",
    "        else:\n",
    "            self.selected_node = self.greedy_node()\n",
    "            self.game_node = self.selected_node\n",
    "    \n",
    "    def update_values(self):\n",
    "        index0 = self.tree.index(self.selected_node)\n",
    "        self.make_move()\n",
    "        index1 = self.tree.index(self.selected_node)\n",
    "        \n",
    "        value0 = self.values[index0['level']][index0['node_number']]\n",
    "        value1 = self.values[index1['level']][index1['node_number']]\n",
    "        \n",
    "        value0_updated = value0 + learning_rate*(value1 - value0)\n",
    "        self.values[index0['level']][index0['node_number']] = value0_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-500-90690541246a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36mmake_move\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreedy_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36mgreedy_node\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgreedy_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprospects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36mprospects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'node_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mprospective_node_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mprospective_nodes_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprospective_node_numbers\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprospective_nodes_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m((node_num,))\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'node_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mprospective_node_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mprospective_nodes_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprospective_node_numbers\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprospective_nodes_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "x = Agent('x', random_frequency = 0.1, learning_rate = 0)\n",
    "o = Agent('o', random_frequency = 0.1, learning_rate = 0.1)\n",
    "x.make_move()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Game():\n",
    "    def __init__(self, agents):\n",
    "        self.state = State('         ')\n",
    "        self.agents = agents\n",
    "        self.score = {k:0 for k,v in agents.iteritems()}\n",
    "    \n",
    "    def is_over(self):\n",
    "        return self.state.is_terminal()\n",
    "    \n",
    "    def play_turn(self):\n",
    "        player = self.state.player()\n",
    "        should_update = (self.agents[player].selected_node != None)\n",
    "        \n",
    "        self.agents[player].make_move()\n",
    "        self.state = State(self.agents[player].selected_node)\n",
    "        \n",
    "        if should_update:\n",
    "            self.agents[player].update_values()\n",
    "    \n",
    "    def play_game(self):\n",
    "        while not self.state.is_terminal():\n",
    "            self.play_turn()\n",
    "        self.score[self.state.winner()] += 1\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.state = State('         ')\n",
    "        \n",
    "    def play_n_games(self, n):\n",
    "        for _ in range(n):\n",
    "            self.reset_state()\n",
    "            self.play_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = Agent('x', random_frequency = 0.1, learning_rate = 0)\n",
    "o = Agent('o', random_frequency = 0.1, learning_rate = 0.1)\n",
    "game = Game({'x':x, 'o':o})\n",
    "#game.play_n_games(300)\n",
    "#game.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-499-aa8129f22427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36mmake_move\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_frequency\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36mrandom_node\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrandom_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprospects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36mprospects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'node_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mprospective_node_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mprospective_nodes_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprospective_node_numbers\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprospective_nodes_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m((node_num,))\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'node_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mprospective_node_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mprospective_nodes_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprospective_node_numbers\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprospective_nodes_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "x.make_move()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-498-1e5acb17d63e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36mmake_move\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreedy_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36mgreedy_node\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgreedy_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprospects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36mprospects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'node_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mprospective_node_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mprospective_nodes_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprospective_node_numbers\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprospective_nodes_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m((node_num,))\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'node_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mprospective_node_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mprospective_nodes_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprospective_node_numbers\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprospective_nodes_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "game.agents[game.state.player()].make_move()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-493-91c2cca24e8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_turn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-488-85b83c0eb279>\u001b[0m in \u001b[0;36mplay_turn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mshould_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_node\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36mmake_move\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreedy_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36mgreedy_node\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgreedy_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprospects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36mprospects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'node_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mprospective_node_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mprospective_nodes_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprospective_node_numbers\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprospective_nodes_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-485-1a7378a13305>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m((node_num,))\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'node_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mprospective_node_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mprospective_nodes_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprospective_node_numbers\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprospective_nodes_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "game.play_turn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif __name__ == \"__main__\":\\n    p1 = Agent(1, lossval = -1)\\n    p2 = Agent(2, lossval = -1)\\n    r1 = Agent(1, learning = False)\\n    r2 = Agent(2, learning = False)\\n    r1.epsilon = 1\\n    r2.epsilon = 1\\n    series = [\\'P1-Win\\',\\'P1-Lose\\',\\'P1-Draw\\',\\'P2-Win\\',\\'P2-Lose\\',\\'P2-Draw\\']\\n    #series = [\\'P1-Win\\', \\'P2-Win\\', \\'Draw\\']\\n    colors = [\\'r\\',\\'b\\',\\'g\\',\\'c\\',\\'m\\',\\'b\\']\\n    markers = [\\'+\\', \\'.\\', \\'o\\', \\'*\\', \\'^\\', \\'s\\']\\n    f = open(\\'results.csv\\', \\'wb\\')\\n    writer = csv.writer(f)    \\n    writer.writerow(series)\\n    perf = [[] for _ in range(len(series) + 1)]\\n    for i in range(10000):\\n        if i % 10 == 0:\\n            print \\'Game: {0}\\'.format(i)\\n            probs = measure_performance_vs_random(p1, p2)\\n            writer.writerow(probs)\\n            f.flush()\\n            perf[0].append(i)\\n            for idx,x in enumerate(probs):\\n                perf[idx+1].append(x)\\n        winner = play(p1,p2)\\n        p1.episode_over(winner)\\n        #winner = play(r1,p2)\\n        p2.episode_over(winner)\\n    f.close()\\n    for i in range(1,len(perf)):\\n        plt.plot(perf[0], perf[i], label=series[i-1], color=colors[i-1])\\n    plt.xlabel(\\'Episodes\\')\\n    plt.ylabel(\\'Probability\\')\\n    plt.title(\\'RL Agent Performance vs. Random Agent\\n({0} loss value, self-play)\\'.format(p1.lossval))\\n    #plt.title(\\'P1 Loss={0} vs. P2 Loss={1}\\'.format(p1.lossval, p2.lossval))\\n    plt.legend()\\n    #plt.show()\\n    #plt.savefig(\\'p1loss{0}vsp2loss{1}.png\\'.format(p1.lossval, p2.lossval))\\n    plt.savefig(\\'selfplay_random_{0}loss.png\\'.format(p1.lossval))\\n    while True:\\n        p2.verbose = True\\n        p1 = Human(1)\\n        winner = play(p1,p2)\\n        p1.episode_over(winner)\\n        p2.episode_over(winner)\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from copy import copy, deepcopy\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EMPTY = 0\n",
    "PLAYER_X = 1\n",
    "PLAYER_O = 2\n",
    "DRAW = 3\n",
    "\n",
    "def emptystate():\n",
    "    return [[EMPTY,EMPTY,EMPTY],[EMPTY,EMPTY,EMPTY],[EMPTY,EMPTY,EMPTY]]\n",
    "\n",
    "def gameover(state):\n",
    "    for i in range(3):\n",
    "        if state[i][0] != EMPTY and state[i][0] == state[i][1] and state[i][0] == state[i][2]:\n",
    "            return state[i][0]\n",
    "        if state[0][i] != EMPTY and state[0][i] == state[1][i] and state[0][i] == state[2][i]:\n",
    "            return state[0][i]\n",
    "    if state[0][0] != EMPTY and state[0][0] == state[1][1] and state[0][0] == state[2][2]:\n",
    "        return state[0][0]\n",
    "    if state[0][2] != EMPTY and state[0][2] == state[1][1] and state[0][2] == state[2][0]:\n",
    "        return state[0][2]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if state[i][j] == EMPTY:\n",
    "                return EMPTY\n",
    "    return DRAW\n",
    "\n",
    "def last_to_act(state):\n",
    "    countx = 0\n",
    "    counto = 0\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if state[i][j] == PLAYER_X:\n",
    "                countx += 1\n",
    "            elif state[i][j] == PLAYER_O:\n",
    "                counto += 1\n",
    "    if countx == counto:\n",
    "        return PLAYER_O\n",
    "    if countx == (counto + 1):\n",
    "        return PLAYER_X\n",
    "    return -1\n",
    "\n",
    "\n",
    "def enumstates(state, idx, agent):\n",
    "    if idx > 8:\n",
    "        player = last_to_act(state)\n",
    "        if player == agent.player:\n",
    "            agent.add(state)\n",
    "    else:\n",
    "        winner = gameover(state)\n",
    "        if winner != EMPTY:\n",
    "            return\n",
    "        i = idx / 3\n",
    "        j = idx % 3\n",
    "        for val in range(3):\n",
    "            state[i][j] = val\n",
    "            enumstates(state, idx+1, agent)\n",
    "\n",
    "class Agent(object):\n",
    "    def __init__(self, player, verbose = False, lossval = 0, learning = True):\n",
    "        self.values = {}\n",
    "        self.player = player\n",
    "        self.verbose = verbose\n",
    "        self.lossval = lossval\n",
    "        self.learning = learning\n",
    "        self.epsilon = 0.1\n",
    "        self.alpha = 0.99\n",
    "        self.prevstate = None\n",
    "        self.prevscore = 0\n",
    "        self.count = 0\n",
    "        enumstates(emptystate(), 0, self)\n",
    "\n",
    "    def episode_over(self, winner):\n",
    "        self.backup(self.winnerval(winner))\n",
    "        self.prevstate = None\n",
    "        self.prevscore = 0\n",
    "\n",
    "    def action(self, state):\n",
    "        r = random.random()\n",
    "        if r < self.epsilon:\n",
    "            move = self.random(state)\n",
    "            self.log('>>>>>>> Exploratory action: ' + str(move))\n",
    "        else:\n",
    "            move = self.greedy(state)\n",
    "            self.log('>>>>>>> Best action: ' + str(move))\n",
    "        state[move[0]][move[1]] = self.player\n",
    "        self.prevstate = self.statetuple(state)\n",
    "        self.prevscore = self.lookup(state)\n",
    "        state[move[0]][move[1]] = EMPTY\n",
    "        return move\n",
    "\n",
    "    def random(self, state):\n",
    "        available = []\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if state[i][j] == EMPTY:\n",
    "                    available.append((i,j))\n",
    "        return random.choice(available)\n",
    "\n",
    "    def greedy(self, state):\n",
    "        maxval = -50000\n",
    "        maxmove = None\n",
    "        if self.verbose:\n",
    "            cells = []\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if state[i][j] == EMPTY:\n",
    "                    state[i][j] = self.player\n",
    "                    val = self.lookup(state)\n",
    "                    state[i][j] = EMPTY\n",
    "                    if val > maxval:\n",
    "                        maxval = val\n",
    "                        maxmove = (i, j)\n",
    "                    if self.verbose:\n",
    "                        cells.append('{0:.3f}'.format(val).center(6))\n",
    "                elif self.verbose:\n",
    "                    cells.append(NAMES[state[i][j]].center(6))\n",
    "        if self.verbose:\n",
    "            print BOARD_FORMAT.format(*cells)\n",
    "        self.backup(maxval)\n",
    "        return maxmove\n",
    "\n",
    "    def backup(self, nextval):\n",
    "        if self.prevstate != None and self.learning:\n",
    "            self.values[self.prevstate] += self.alpha * (nextval - self.prevscore)\n",
    "\n",
    "    def lookup(self, state):\n",
    "        key = self.statetuple(state)\n",
    "        if not key in self.values:\n",
    "            self.add(key)\n",
    "        return self.values[key]\n",
    "\n",
    "    def add(self, state):\n",
    "        winner = gameover(state)\n",
    "        tup = self.statetuple(state)\n",
    "        self.values[tup] = self.winnerval(winner)\n",
    "\n",
    "    def winnerval(self, winner):\n",
    "        if winner == self.player:\n",
    "            return 1\n",
    "        elif winner == EMPTY:\n",
    "            return 0.5\n",
    "        elif winner == DRAW:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.lossval\n",
    "\n",
    "    def printvalues(self):\n",
    "        vals = deepcopy(self.values)\n",
    "        for key in vals:\n",
    "            state = [list(key[0]),list(key[1]),list(key[2])]\n",
    "            cells = []\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    if state[i][j] == EMPTY:\n",
    "                        state[i][j] = self.player\n",
    "                        cells.append(str(self.lookup(state)).center(3))\n",
    "                        state[i][j] = EMPTY\n",
    "                    else:\n",
    "                        cells.append(NAMES[state[i][j]].center(3))\n",
    "            print BOARD_FORMAT.format(*cells)\n",
    "\n",
    "    def statetuple(self, state):\n",
    "        return (tuple(state[0]),tuple(state[1]),tuple(state[2]))\n",
    "\n",
    "    def log(self, s):\n",
    "        if self.verbose:\n",
    "            print s\n",
    "\n",
    "class Human(object):\n",
    "    def __init__(self, player):\n",
    "        self.player = player\n",
    "\n",
    "    def action(self, state):\n",
    "        printboard(state)\n",
    "        action = raw_input('Your move? ')\n",
    "        return (int(action.split(',')[0]),int(action.split(',')[1]))\n",
    "\n",
    "    def episode_over(self, winner):\n",
    "        if winner == DRAW:\n",
    "            print 'Game over! It was a draw.'\n",
    "        else:\n",
    "            print 'Game over! Winner: Player {0}'.format(winner)\n",
    "\n",
    "def play(agent1, agent2):\n",
    "    state = emptystate()\n",
    "    for i in range(9):\n",
    "        if i % 2 == 0:\n",
    "            move = agent1.action(state)\n",
    "        else:\n",
    "            move = agent2.action(state)\n",
    "        state[move[0]][move[1]] = (i % 2) + 1\n",
    "        winner = gameover(state)\n",
    "        if winner != EMPTY:\n",
    "            return winner\n",
    "    return winner\n",
    "\n",
    "def measure_performance_vs_random(agent1, agent2):\n",
    "    epsilon1 = agent1.epsilon\n",
    "    epsilon2 = agent2.epsilon\n",
    "    agent1.epsilon = 0\n",
    "    agent2.epsilon = 0\n",
    "    agent1.learning = False\n",
    "    agent2.learning = False\n",
    "    r1 = Agent(1)\n",
    "    r2 = Agent(2)\n",
    "    r1.epsilon = 1\n",
    "    r2.epsilon = 1\n",
    "    probs = [0,0,0,0,0,0]\n",
    "    games = 100\n",
    "    for i in range(games):\n",
    "        winner = play(agent1, r2)\n",
    "        if winner == PLAYER_X:\n",
    "            probs[0] += 1.0 / games\n",
    "        elif winner == PLAYER_O:\n",
    "            probs[1] += 1.0 / games\n",
    "        else:\n",
    "            probs[2] += 1.0 / games\n",
    "    for i in range(games):\n",
    "        winner = play(r1, agent2)\n",
    "        if winner == PLAYER_O:\n",
    "            probs[3] += 1.0 / games\n",
    "        elif winner == PLAYER_X:\n",
    "            probs[4] += 1.0 / games\n",
    "        else:\n",
    "            probs[5] += 1.0 / games\n",
    "    agent1.epsilon = epsilon1\n",
    "    agent2.epsilon = epsilon2\n",
    "    agent1.learning = True\n",
    "    agent2.learning = True\n",
    "    return probs\n",
    "\n",
    "def measure_performance_vs_each_other(agent1, agent2):\n",
    "    #epsilon1 = agent1.epsilon\n",
    "    #epsilon2 = agent2.epsilon\n",
    "    #agent1.epsilon = 0\n",
    "    #agent2.epsilon = 0\n",
    "    #agent1.learning = False\n",
    "    #agent2.learning = False\n",
    "    probs = [0,0,0]\n",
    "    games = 100\n",
    "    for i in range(games):\n",
    "        winner = play(agent1, agent2)\n",
    "        if winner == PLAYER_X:\n",
    "            probs[0] += 1.0 / games\n",
    "        elif winner == PLAYER_O:\n",
    "            probs[1] += 1.0 / games\n",
    "        else:\n",
    "            probs[2] += 1.0 / games\n",
    "    #agent1.epsilon = epsilon1\n",
    "    #agent2.epsilon = epsilon2\n",
    "    #agent1.learning = True\n",
    "    #agent2.learning = True\n",
    "    return probs\n",
    "\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    p1 = Agent(1, lossval = -1)\n",
    "    p2 = Agent(2, lossval = -1)\n",
    "    r1 = Agent(1, learning = False)\n",
    "    r2 = Agent(2, learning = False)\n",
    "    r1.epsilon = 1\n",
    "    r2.epsilon = 1\n",
    "    series = ['P1-Win','P1-Lose','P1-Draw','P2-Win','P2-Lose','P2-Draw']\n",
    "    #series = ['P1-Win', 'P2-Win', 'Draw']\n",
    "    colors = ['r','b','g','c','m','b']\n",
    "    markers = ['+', '.', 'o', '*', '^', 's']\n",
    "    f = open('results.csv', 'wb')\n",
    "    writer = csv.writer(f)    \n",
    "    writer.writerow(series)\n",
    "    perf = [[] for _ in range(len(series) + 1)]\n",
    "    for i in range(10000):\n",
    "        if i % 10 == 0:\n",
    "            print 'Game: {0}'.format(i)\n",
    "            probs = measure_performance_vs_random(p1, p2)\n",
    "            writer.writerow(probs)\n",
    "            f.flush()\n",
    "            perf[0].append(i)\n",
    "            for idx,x in enumerate(probs):\n",
    "                perf[idx+1].append(x)\n",
    "        winner = play(p1,p2)\n",
    "        p1.episode_over(winner)\n",
    "        #winner = play(r1,p2)\n",
    "        p2.episode_over(winner)\n",
    "    f.close()\n",
    "    for i in range(1,len(perf)):\n",
    "        plt.plot(perf[0], perf[i], label=series[i-1], color=colors[i-1])\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('RL Agent Performance vs. Random Agent\\n({0} loss value, self-play)'.format(p1.lossval))\n",
    "    #plt.title('P1 Loss={0} vs. P2 Loss={1}'.format(p1.lossval, p2.lossval))\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "    #plt.savefig('p1loss{0}vsp2loss{1}.png'.format(p1.lossval, p2.lossval))\n",
    "    plt.savefig('selfplay_random_{0}loss.png'.format(p1.lossval))\n",
    "    while True:\n",
    "        p2.verbose = True\n",
    "        p1 = Human(1)\n",
    "        winner = play(p1,p2)\n",
    "        p1.episode_over(winner)\n",
    "        p2.episode_over(winner)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
